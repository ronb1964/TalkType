[tool.poetry]
name = "talktype"
version = "0.5.12"
description = "Press-and-hold dictation for Wayland (F8), Faster-Whisper + ydotool, with smart punctuation."
authors = ["Ron"]
license = "MIT"
readme = "README.md"
packages = [{ include = "talktype", from = "src" }]

[tool.poetry.dependencies]
python = ">=3.10,<3.15"  # Dev: 3.14 (Nobara 42), AppImage: 3.10 (Ubuntu 22.04)
faster-whisper = "*"
sounddevice = "*"
evdev = "*"
numpy = "*"
pyperclip = "*"
toml = "*"
# pygobject - using system package (copied manually in build script)
# pycairo - using system package (copied manually in build script)
# PyTorch CPU-only: TalkType uses faster-whisper/CTranslate2 for inference (not PyTorch)
# PyTorch is only needed for HuggingFace model downloading
torch = {version = "^2.9.0", source = "pytorch-cpu"}
# torchvision/torchaudio removed - not needed, only torch required for HuggingFace Hub

[tool.poetry.scripts]
dictate-tray = "talktype.tray:main"
dictate = "talktype.app:main"
dictate-prefs = "talktype.prefs:main"

[tool.poetry.group.dev.dependencies]
pytest = "^8.4.1"
black = "^25.1.0"
ruff = "^0.12.9"


# PyTorch CPU-only source - saves ~600MB in AppImage
# GPU acceleration uses CTranslate2's CUDA support (downloaded separately via cuda_helper.py)
[[tool.poetry.source]]
name = "pytorch-cpu"
url = "https://download.pytorch.org/whl/cpu"
priority = "explicit"

[tool.black]
line-length = 100

[tool.ruff]
line-length = 100
select = ["E","F","I"]

[tool.pytest.ini_options]
testpaths = ["tests"]

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"
